CodeBroker
{
	akka {

			  log-dead-letters = 10
			  log-dead-letters-during-shutdown = on
			  loggers = ["akka.event.slf4j.Slf4jLogger"]
			  loglevel = "DEBUG"
			  actor {
				  provider = "cluster"

				  debug {
				      receive = on
				      autoreceive = on
				      lifecycle = on
				   }

				  serializers
					{
					  proto = "akka.remote.serialization.ProtobufSerializer"
					  myown = "com.codebroker.protocol.serialization.CodeBrokerRemoteSerializatier"
					}
					serialization-bindings
					{
					   "com.google.protobuf.Message" = proto
					   "com.codebroker.core.data.IObject" = myown
					   "com.codebroker.core.data.IArray" = myown
					   "com.codebroker.api.event.Event" = myown
					}
				}
				
				remote {
					  log-remote-lifecycle-events = off
					  netty.tcp {
					      hostname = "192.168.0.127"
					      port = 2551
					 }
					  
				}
				
				cluster 
				{
	  
						seed-nodes = [
									  "akka.tcp://CodeBroker@192.168.0.127:2551",
									  "akka.tcp://CodeBroker@192.168.0.202:2551"
									  ]
									  
						seed-node-timeout = 30s
						down-removal-margin = off

						quarantine-removed-node-after=30s
						allow-weakly-up-members = on
						
						auto-down-unreachable-after = 10s

						log-info = on
						jmx.enabled = on
						jmx.multi-mbeans-in-same-jvm = off
						# how often should the node send out gossip information?
						gossip-interval = 30s
						gossip-time-to-live = 60s
						leader-actions-interval = 30s
						unreachable-nodes-reaper-interval = 30s
						
						scheduler {
						  tick-duration = 33ms
						  ticks-per-wheel = 512
						}

						debug {
						  verbose-heartbeat-logging = off
						}
						
				}
		
     }
	  akka.kafka.producer {
	  # Tuning parameter of how many sends that can run in parallel.
	  parallelism = 100
	  
	  # How long to wait for `KafkaProducer.close`
	  close-timeout = 60s
	  
	  # Fully qualified config path which holds the dispatcher configuration
	  # to be used by the producer stages. Some blocking may occur.
	  # When this value is empty, the dispatcher configured for the stream
	  # will be used.
	  use-dispatcher = "akka.kafka.default-dispatcher"
	
	  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
	  # can be defined in this configuration section.
	  kafka-clients {
	  }
	}
	akka.kafka.consumer {
	  # Tuning property of scheduled polls.
	  poll-interval = 50ms
	  
	  # Tuning property of the `KafkaConsumer.poll` parameter.
	  # Note that non-zero value means that blocking of the thread that
	  # is executing the stage will be blocked.
	  poll-timeout = 50ms
	  
	  # The stage will be await outstanding offset commit requests before
	  # shutting down, but if that takes longer than this timeout it will
	  # stop forcefully.
	  stop-timeout = 30s
	  
	  # How long to wait for `KafkaConsumer.close`
	  close-timeout = 20s
	  
	  # If offset commit requests are not completed within this timeout
	  # the returned Future is completed `TimeoutException`.
	  commit-timeout = 15s
	  
	  # If the KafkaConsumer can't connect to the broker the poll will be
	  # aborted after this timeout. The KafkaConsumerActor will throw
	  # org.apache.kafka.common.errors.WakeupException which will be ignored
	  # until max-wakeups limit gets exceeded.
	  wakeup-timeout = 3s
	
	  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
	  max-wakeups = 10
	  
	  # Fully qualified config path which holds the dispatcher configuration
	  # to be used by the KafkaConsumerActor. Some blocking may occur.
	  use-dispatcher = "akka.kafka.default-dispatcher"
	
	  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
	  # can be defined in this configuration section.
	  kafka-clients {
	    # Disable auto-commit by default
	    enable.auto.commit = false
	  }
	}
 }